{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SimpleImputer\n",
    "### This notebook outlines the usage of Simple Imputer (Univariate Imputation).\n",
    "### Simple Imputer substitutes missing values statistics (mean, median, ...)\n",
    "#### Dataset: [https://github.com/subashgandyer/datasets/blob/main/heart_disease.csv]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Demographic**\n",
    "- Sex: male or female(Nominal)\n",
    "- Age: Age of the patient;(Continuous - Although the recorded ages have been truncated to whole numbers, the concept of age is continuous)\n",
    "\n",
    "**Behavioral**\n",
    "- Current Smoker: whether or not the patient is a current smoker (Nominal)\n",
    "- Cigs Per Day: the number of cigarettes that the person smoked on average in one day.(can be considered continuous as one can have any number of cigarettes, even half a cigarette.)\n",
    "\n",
    "**Medical(history)**\n",
    "- BP Meds: whether or not the patient was on blood pressure medication (Nominal)\n",
    "- Prevalent Stroke: whether or not the patient had previously had a stroke (Nominal)\n",
    "- Prevalent Hyp: whether or not the patient was hypertensive (Nominal)\n",
    "- Diabetes: whether or not the patient had diabetes (Nominal)\n",
    "\n",
    "**Medical(current)**\n",
    "- Tot Chol: total cholesterol level (Continuous)\n",
    "- Sys BP: systolic blood pressure (Continuous)\n",
    "- Dia BP: diastolic blood pressure (Continuous)\n",
    "- BMI: Body Mass Index (Continuous)\n",
    "- Heart Rate: heart rate (Continuous - In medical research, variables such as heart rate though in fact discrete, yet are considered continuous because of large number of possible values.)\n",
    "- Glucose: glucose level (Continuous)\n",
    "\n",
    "**Predict variable (desired target)**\n",
    "- 10 year risk of coronary heart disease CHD (binary: “1”, means “Yes”, “0” means “No”)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>male</th>\n",
       "      <th>age</th>\n",
       "      <th>education</th>\n",
       "      <th>currentSmoker</th>\n",
       "      <th>cigsPerDay</th>\n",
       "      <th>BPMeds</th>\n",
       "      <th>prevalentStroke</th>\n",
       "      <th>prevalentHyp</th>\n",
       "      <th>diabetes</th>\n",
       "      <th>totChol</th>\n",
       "      <th>sysBP</th>\n",
       "      <th>diaBP</th>\n",
       "      <th>BMI</th>\n",
       "      <th>heartRate</th>\n",
       "      <th>glucose</th>\n",
       "      <th>TenYearCHD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>26.97</td>\n",
       "      <td>80.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>28.73</td>\n",
       "      <td>95.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>48</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>127.5</td>\n",
       "      <td>80.0</td>\n",
       "      <td>25.34</td>\n",
       "      <td>75.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>61</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>225.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>28.58</td>\n",
       "      <td>65.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>285.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>23.10</td>\n",
       "      <td>85.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4233</th>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>313.0</td>\n",
       "      <td>179.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>25.97</td>\n",
       "      <td>66.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4234</th>\n",
       "      <td>1</td>\n",
       "      <td>51</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>43.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>207.0</td>\n",
       "      <td>126.5</td>\n",
       "      <td>80.0</td>\n",
       "      <td>19.71</td>\n",
       "      <td>65.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4235</th>\n",
       "      <td>0</td>\n",
       "      <td>48</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>20.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>248.0</td>\n",
       "      <td>131.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>22.00</td>\n",
       "      <td>84.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4236</th>\n",
       "      <td>0</td>\n",
       "      <td>44</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>210.0</td>\n",
       "      <td>126.5</td>\n",
       "      <td>87.0</td>\n",
       "      <td>19.16</td>\n",
       "      <td>86.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4237</th>\n",
       "      <td>0</td>\n",
       "      <td>52</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>269.0</td>\n",
       "      <td>133.5</td>\n",
       "      <td>83.0</td>\n",
       "      <td>21.47</td>\n",
       "      <td>80.0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4238 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      male  age  education  currentSmoker  cigsPerDay  BPMeds  \\\n",
       "0        1   39        4.0              0         0.0     0.0   \n",
       "1        0   46        2.0              0         0.0     0.0   \n",
       "2        1   48        1.0              1        20.0     0.0   \n",
       "3        0   61        3.0              1        30.0     0.0   \n",
       "4        0   46        3.0              1        23.0     0.0   \n",
       "...    ...  ...        ...            ...         ...     ...   \n",
       "4233     1   50        1.0              1         1.0     0.0   \n",
       "4234     1   51        3.0              1        43.0     0.0   \n",
       "4235     0   48        2.0              1        20.0     NaN   \n",
       "4236     0   44        1.0              1        15.0     0.0   \n",
       "4237     0   52        2.0              0         0.0     0.0   \n",
       "\n",
       "      prevalentStroke  prevalentHyp  diabetes  totChol  sysBP  diaBP    BMI  \\\n",
       "0                   0             0         0    195.0  106.0   70.0  26.97   \n",
       "1                   0             0         0    250.0  121.0   81.0  28.73   \n",
       "2                   0             0         0    245.0  127.5   80.0  25.34   \n",
       "3                   0             1         0    225.0  150.0   95.0  28.58   \n",
       "4                   0             0         0    285.0  130.0   84.0  23.10   \n",
       "...               ...           ...       ...      ...    ...    ...    ...   \n",
       "4233                0             1         0    313.0  179.0   92.0  25.97   \n",
       "4234                0             0         0    207.0  126.5   80.0  19.71   \n",
       "4235                0             0         0    248.0  131.0   72.0  22.00   \n",
       "4236                0             0         0    210.0  126.5   87.0  19.16   \n",
       "4237                0             0         0    269.0  133.5   83.0  21.47   \n",
       "\n",
       "      heartRate  glucose  TenYearCHD  \n",
       "0          80.0     77.0           0  \n",
       "1          95.0     76.0           0  \n",
       "2          75.0     70.0           0  \n",
       "3          65.0    103.0           1  \n",
       "4          85.0     85.0           0  \n",
       "...         ...      ...         ...  \n",
       "4233       66.0     86.0           1  \n",
       "4234       65.0     68.0           0  \n",
       "4235       84.0     86.0           0  \n",
       "4236       86.0      NaN           0  \n",
       "4237       80.0    107.0           0  \n",
       "\n",
       "[4238 rows x 16 columns]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv(\"heart_disease.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How many Categorical variables in the dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4238 entries, 0 to 4237\n",
      "Data columns (total 16 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   male             4238 non-null   int64  \n",
      " 1   age              4238 non-null   int64  \n",
      " 2   education        4133 non-null   float64\n",
      " 3   currentSmoker    4238 non-null   int64  \n",
      " 4   cigsPerDay       4209 non-null   float64\n",
      " 5   BPMeds           4185 non-null   float64\n",
      " 6   prevalentStroke  4238 non-null   int64  \n",
      " 7   prevalentHyp     4238 non-null   int64  \n",
      " 8   diabetes         4238 non-null   int64  \n",
      " 9   totChol          4188 non-null   float64\n",
      " 10  sysBP            4238 non-null   float64\n",
      " 11  diaBP            4238 non-null   float64\n",
      " 12  BMI              4219 non-null   float64\n",
      " 13  heartRate        4237 non-null   float64\n",
      " 14  glucose          3850 non-null   float64\n",
      " 15  TenYearCHD       4238 non-null   int64  \n",
      "dtypes: float64(9), int64(7)\n",
      "memory usage: 529.9 KB\n",
      "List of categorical feature names including education:\n",
      "['male', 'currentSmoker', 'prevalentStroke', 'prevalentHyp', 'diabetes', 'TenYearCHD', 'education']\n",
      "There are 7 categorical features\n"
     ]
    }
   ],
   "source": [
    "df.info()\n",
    "\n",
    "categorical_feature_names = []\n",
    "\n",
    "for feature_name in df.columns:\n",
    "    unique_values = df[feature_name].unique()\n",
    "\n",
    "    # Check if the feature has only the values 1 and 0\n",
    "    if set(unique_values) == {0, 1}:\n",
    "        categorical_feature_names.append(feature_name)\n",
    "\n",
    "print(\"List of categorical feature names including education:\")\n",
    "categorical_feature_names.append('education')\n",
    "print(categorical_feature_names)\n",
    "print(f\"There are {len(categorical_feature_names)} categorical features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How many Missing values in the dataset?\n",
    "Hint: df.Series.isna( ).sum( )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "male >> Missing entries: 0  |  Percentage: 0.0\n",
      "age >> Missing entries: 0  |  Percentage: 0.0\n",
      "education >> Missing entries: 105  |  Percentage: 2.48\n",
      "currentSmoker >> Missing entries: 0  |  Percentage: 0.0\n",
      "cigsPerDay >> Missing entries: 29  |  Percentage: 0.68\n",
      "BPMeds >> Missing entries: 53  |  Percentage: 1.25\n",
      "prevalentStroke >> Missing entries: 0  |  Percentage: 0.0\n",
      "prevalentHyp >> Missing entries: 0  |  Percentage: 0.0\n",
      "diabetes >> Missing entries: 0  |  Percentage: 0.0\n",
      "totChol >> Missing entries: 50  |  Percentage: 1.18\n",
      "sysBP >> Missing entries: 0  |  Percentage: 0.0\n",
      "diaBP >> Missing entries: 0  |  Percentage: 0.0\n",
      "BMI >> Missing entries: 19  |  Percentage: 0.45\n",
      "heartRate >> Missing entries: 1  |  Percentage: 0.02\n",
      "glucose >> Missing entries: 388  |  Percentage: 9.16\n",
      "TenYearCHD >> Missing entries: 0  |  Percentage: 0.0\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(df.columns)):\n",
    "    missing_data = df[df.columns[i]].isna().sum()\n",
    "    perc = missing_data / len(df) * 100\n",
    "    print(f'{df.columns[i]} >> Missing entries: {missing_data}  |  Percentage: {round(perc, 2)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bonus: Visual representation of missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "sns.heatmap(df.isna(), cbar=False, cmap='viridis', yticklabels=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import SimpleImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create SimpleImputer object with 'mean' strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer = SimpleImputer(strategy='mean')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optional - converting df into numpy array (There is a way to directly impute from dataframe as well)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_array = df.values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data[:, :-1]\n",
    "y = data[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit the imputer model on dataset to calculate statistic for each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Imputation statistics for each column:\n",
      "male                 0.429212\n",
      "age                 49.584946\n",
      "education            1.978950\n",
      "currentSmoker        0.494101\n",
      "cigsPerDay           9.003089\n",
      "BPMeds               0.029630\n",
      "prevalentStroke      0.005899\n",
      "prevalentHyp         0.310524\n",
      "diabetes             0.025720\n",
      "totChol            236.721585\n",
      "sysBP              132.352407\n",
      "diaBP               82.893464\n",
      "BMI                 25.802008\n",
      "heartRate           75.878924\n",
      "glucose             81.966753\n",
      "TenYearCHD           0.151958\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "imputer.fit(df)\n",
    "\n",
    "# Now, you can access the statistics for each column\n",
    "df_imputed = pd.Series(imputer.statistics_, index=df.columns)\n",
    "\n",
    "# Display the calculated statistics\n",
    "print(\"\\nImputation statistics for each column:\")\n",
    "print(df_imputted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trained imputer model is applied to dataset to create a copy of dataset with all filled missing values from the calculated statistic using transform( ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Apply imputation on the DataFrame\n",
    "df_imputed = pd.DataFrame(imputer.fit_transform(df), columns=df.columns)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sanity Check: Whether missing values are filled or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of missing values after imputation:\n",
      "male               0\n",
      "age                0\n",
      "education          0\n",
      "currentSmoker      0\n",
      "cigsPerDay         0\n",
      "BPMeds             0\n",
      "prevalentStroke    0\n",
      "prevalentHyp       0\n",
      "diabetes           0\n",
      "totChol            0\n",
      "sysBP              0\n",
      "diaBP              0\n",
      "BMI                0\n",
      "heartRate          0\n",
      "glucose            0\n",
      "TenYearCHD         0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check the missing values in the imputed DataFrame\n",
    "print(\"\\nNumber of missing values after imputation:\")\n",
    "print(df_imputed.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's try to visualize the missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "sns.heatmap(df_imputed.isna(), cbar=False, cmap='viridis', yticklabels=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What's the issue here?\n",
    "#### Hint: Heatmap needs a DataFrame and not a Numpy Array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>male</th>\n",
       "      <th>age</th>\n",
       "      <th>education</th>\n",
       "      <th>currentSmoker</th>\n",
       "      <th>cigsPerDay</th>\n",
       "      <th>BPMeds</th>\n",
       "      <th>prevalentStroke</th>\n",
       "      <th>prevalentHyp</th>\n",
       "      <th>diabetes</th>\n",
       "      <th>totChol</th>\n",
       "      <th>sysBP</th>\n",
       "      <th>diaBP</th>\n",
       "      <th>BMI</th>\n",
       "      <th>heartRate</th>\n",
       "      <th>glucose</th>\n",
       "      <th>TenYearCHD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>26.97</td>\n",
       "      <td>80.0</td>\n",
       "      <td>77.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>28.73</td>\n",
       "      <td>95.0</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>127.5</td>\n",
       "      <td>80.0</td>\n",
       "      <td>25.34</td>\n",
       "      <td>75.0</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>225.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>28.58</td>\n",
       "      <td>65.0</td>\n",
       "      <td>103.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>285.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>23.10</td>\n",
       "      <td>85.0</td>\n",
       "      <td>85.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4233</th>\n",
       "      <td>1.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>313.0</td>\n",
       "      <td>179.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>25.97</td>\n",
       "      <td>66.0</td>\n",
       "      <td>86.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4234</th>\n",
       "      <td>1.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>207.0</td>\n",
       "      <td>126.5</td>\n",
       "      <td>80.0</td>\n",
       "      <td>19.71</td>\n",
       "      <td>65.0</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4235</th>\n",
       "      <td>0.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.02963</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>248.0</td>\n",
       "      <td>131.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>22.00</td>\n",
       "      <td>84.0</td>\n",
       "      <td>86.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4236</th>\n",
       "      <td>0.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>210.0</td>\n",
       "      <td>126.5</td>\n",
       "      <td>87.0</td>\n",
       "      <td>19.16</td>\n",
       "      <td>86.0</td>\n",
       "      <td>81.966753</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4237</th>\n",
       "      <td>0.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>269.0</td>\n",
       "      <td>133.5</td>\n",
       "      <td>83.0</td>\n",
       "      <td>21.47</td>\n",
       "      <td>80.0</td>\n",
       "      <td>107.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4238 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      male   age  education  currentSmoker  cigsPerDay   BPMeds  \\\n",
       "0      1.0  39.0        4.0            0.0         0.0  0.00000   \n",
       "1      0.0  46.0        2.0            0.0         0.0  0.00000   \n",
       "2      1.0  48.0        1.0            1.0        20.0  0.00000   \n",
       "3      0.0  61.0        3.0            1.0        30.0  0.00000   \n",
       "4      0.0  46.0        3.0            1.0        23.0  0.00000   \n",
       "...    ...   ...        ...            ...         ...      ...   \n",
       "4233   1.0  50.0        1.0            1.0         1.0  0.00000   \n",
       "4234   1.0  51.0        3.0            1.0        43.0  0.00000   \n",
       "4235   0.0  48.0        2.0            1.0        20.0  0.02963   \n",
       "4236   0.0  44.0        1.0            1.0        15.0  0.00000   \n",
       "4237   0.0  52.0        2.0            0.0         0.0  0.00000   \n",
       "\n",
       "      prevalentStroke  prevalentHyp  diabetes  totChol  sysBP  diaBP    BMI  \\\n",
       "0                 0.0           0.0       0.0    195.0  106.0   70.0  26.97   \n",
       "1                 0.0           0.0       0.0    250.0  121.0   81.0  28.73   \n",
       "2                 0.0           0.0       0.0    245.0  127.5   80.0  25.34   \n",
       "3                 0.0           1.0       0.0    225.0  150.0   95.0  28.58   \n",
       "4                 0.0           0.0       0.0    285.0  130.0   84.0  23.10   \n",
       "...               ...           ...       ...      ...    ...    ...    ...   \n",
       "4233              0.0           1.0       0.0    313.0  179.0   92.0  25.97   \n",
       "4234              0.0           0.0       0.0    207.0  126.5   80.0  19.71   \n",
       "4235              0.0           0.0       0.0    248.0  131.0   72.0  22.00   \n",
       "4236              0.0           0.0       0.0    210.0  126.5   87.0  19.16   \n",
       "4237              0.0           0.0       0.0    269.0  133.5   83.0  21.47   \n",
       "\n",
       "      heartRate     glucose  TenYearCHD  \n",
       "0          80.0   77.000000         0.0  \n",
       "1          95.0   76.000000         0.0  \n",
       "2          75.0   70.000000         0.0  \n",
       "3          65.0  103.000000         1.0  \n",
       "4          85.0   85.000000         0.0  \n",
       "...         ...         ...         ...  \n",
       "4233       66.0   86.000000         1.0  \n",
       "4234       65.0   68.000000         0.0  \n",
       "4235       84.0   86.000000         0.0  \n",
       "4236       86.0   81.966753         0.0  \n",
       "4237       80.0  107.000000         0.0  \n",
       "\n",
       "[4238 rows x 16 columns]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_imputed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check if these datasets contain missing data\n",
    "### Load the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv(\"X_train.csv\")\n",
    "Y_train = pd.read_csv(\"Y_train.csv\")\n",
    "Y_test = pd.read_csv(\"Y_test.csv\")\n",
    "X_test = pd.read_csv(\"X_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((384, 12), (384, 1), (96, 12), (96, 1))"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, Y_train.shape, X_test.shape, Y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x1200 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set up subplots\n",
    "plt.figure(figsize=(12, 12))\n",
    "\n",
    "# Plot for X_train\n",
    "plt.subplot(2, 2, 1)\n",
    "sns.heatmap(X_train.isna(), cbar=False, cmap='viridis', yticklabels=False)\n",
    "plt.title('X_train Missing Values')\n",
    "\n",
    "# Plot for X_test\n",
    "plt.subplot(2, 2, 2)\n",
    "sns.heatmap(X_test.isna(), cbar=False, cmap='viridis', yticklabels=False)\n",
    "plt.title('X_test Missing Values')\n",
    "\n",
    "# Plot for Y_train\n",
    "plt.subplot(2, 2, 3)\n",
    "sns.heatmap(Y_train.isna(), cbar=False, cmap='viridis', yticklabels=False)\n",
    "plt.title('Y_train Missing Values')\n",
    "\n",
    "# Plot for Y_test\n",
    "plt.subplot(2, 2, 4)\n",
    "sns.heatmap(Y_test.isna(), cbar=False, cmap='viridis', yticklabels=False)\n",
    "plt.title('Y_test Missing Values')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Is there missing data in this dataset???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "#No, there isn't any missing data in dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build a Logistic Regression model Without imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"heart_disease.csv\")\n",
    "X = df[df.columns[:-1]].fillna(method='ffill')\n",
    "y = df[df.columns[-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8496932515337423\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\macwa\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "model.fit(X, y)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y, y_pred)\n",
    "print(f\"Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Drop all rows with missing entries - Build a Logistic Regression model and benchmark the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold, cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>male</th>\n",
       "      <th>age</th>\n",
       "      <th>education</th>\n",
       "      <th>currentSmoker</th>\n",
       "      <th>cigsPerDay</th>\n",
       "      <th>BPMeds</th>\n",
       "      <th>prevalentStroke</th>\n",
       "      <th>prevalentHyp</th>\n",
       "      <th>diabetes</th>\n",
       "      <th>totChol</th>\n",
       "      <th>sysBP</th>\n",
       "      <th>diaBP</th>\n",
       "      <th>BMI</th>\n",
       "      <th>heartRate</th>\n",
       "      <th>glucose</th>\n",
       "      <th>TenYearCHD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>26.97</td>\n",
       "      <td>80.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>28.73</td>\n",
       "      <td>95.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>48</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>127.5</td>\n",
       "      <td>80.0</td>\n",
       "      <td>25.34</td>\n",
       "      <td>75.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>61</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>225.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>28.58</td>\n",
       "      <td>65.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>285.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>23.10</td>\n",
       "      <td>85.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4233</th>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>313.0</td>\n",
       "      <td>179.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>25.97</td>\n",
       "      <td>66.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4234</th>\n",
       "      <td>1</td>\n",
       "      <td>51</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>43.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>207.0</td>\n",
       "      <td>126.5</td>\n",
       "      <td>80.0</td>\n",
       "      <td>19.71</td>\n",
       "      <td>65.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4235</th>\n",
       "      <td>0</td>\n",
       "      <td>48</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>20.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>248.0</td>\n",
       "      <td>131.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>22.00</td>\n",
       "      <td>84.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4236</th>\n",
       "      <td>0</td>\n",
       "      <td>44</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>210.0</td>\n",
       "      <td>126.5</td>\n",
       "      <td>87.0</td>\n",
       "      <td>19.16</td>\n",
       "      <td>86.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4237</th>\n",
       "      <td>0</td>\n",
       "      <td>52</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>269.0</td>\n",
       "      <td>133.5</td>\n",
       "      <td>83.0</td>\n",
       "      <td>21.47</td>\n",
       "      <td>80.0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4238 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      male  age  education  currentSmoker  cigsPerDay  BPMeds  \\\n",
       "0        1   39        4.0              0         0.0     0.0   \n",
       "1        0   46        2.0              0         0.0     0.0   \n",
       "2        1   48        1.0              1        20.0     0.0   \n",
       "3        0   61        3.0              1        30.0     0.0   \n",
       "4        0   46        3.0              1        23.0     0.0   \n",
       "...    ...  ...        ...            ...         ...     ...   \n",
       "4233     1   50        1.0              1         1.0     0.0   \n",
       "4234     1   51        3.0              1        43.0     0.0   \n",
       "4235     0   48        2.0              1        20.0     NaN   \n",
       "4236     0   44        1.0              1        15.0     0.0   \n",
       "4237     0   52        2.0              0         0.0     0.0   \n",
       "\n",
       "      prevalentStroke  prevalentHyp  diabetes  totChol  sysBP  diaBP    BMI  \\\n",
       "0                   0             0         0    195.0  106.0   70.0  26.97   \n",
       "1                   0             0         0    250.0  121.0   81.0  28.73   \n",
       "2                   0             0         0    245.0  127.5   80.0  25.34   \n",
       "3                   0             1         0    225.0  150.0   95.0  28.58   \n",
       "4                   0             0         0    285.0  130.0   84.0  23.10   \n",
       "...               ...           ...       ...      ...    ...    ...    ...   \n",
       "4233                0             1         0    313.0  179.0   92.0  25.97   \n",
       "4234                0             0         0    207.0  126.5   80.0  19.71   \n",
       "4235                0             0         0    248.0  131.0   72.0  22.00   \n",
       "4236                0             0         0    210.0  126.5   87.0  19.16   \n",
       "4237                0             0         0    269.0  133.5   83.0  21.47   \n",
       "\n",
       "      heartRate  glucose  TenYearCHD  \n",
       "0          80.0     77.0           0  \n",
       "1          95.0     76.0           0  \n",
       "2          75.0     70.0           0  \n",
       "3          65.0    103.0           1  \n",
       "4          85.0     85.0           0  \n",
       "...         ...      ...         ...  \n",
       "4233       66.0     86.0           1  \n",
       "4234       65.0     68.0           0  \n",
       "4235       84.0     86.0           0  \n",
       "4236       86.0      NaN           0  \n",
       "4237       80.0    107.0           0  \n",
       "\n",
       "[4238 rows x 16 columns]"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv(\"heart_disease.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4238, 16)"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop rows with missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dropped=df.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split dataset into X and y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>male</th>\n",
       "      <th>age</th>\n",
       "      <th>education</th>\n",
       "      <th>currentSmoker</th>\n",
       "      <th>cigsPerDay</th>\n",
       "      <th>BPMeds</th>\n",
       "      <th>prevalentStroke</th>\n",
       "      <th>prevalentHyp</th>\n",
       "      <th>diabetes</th>\n",
       "      <th>totChol</th>\n",
       "      <th>sysBP</th>\n",
       "      <th>diaBP</th>\n",
       "      <th>BMI</th>\n",
       "      <th>heartRate</th>\n",
       "      <th>glucose</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>26.97</td>\n",
       "      <td>80.0</td>\n",
       "      <td>77.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>28.73</td>\n",
       "      <td>95.0</td>\n",
       "      <td>76.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>48</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>127.5</td>\n",
       "      <td>80.0</td>\n",
       "      <td>25.34</td>\n",
       "      <td>75.0</td>\n",
       "      <td>70.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>61</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>225.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>28.58</td>\n",
       "      <td>65.0</td>\n",
       "      <td>103.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>285.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>23.10</td>\n",
       "      <td>85.0</td>\n",
       "      <td>85.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4231</th>\n",
       "      <td>1</td>\n",
       "      <td>58</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>187.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>24.96</td>\n",
       "      <td>80.0</td>\n",
       "      <td>81.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4232</th>\n",
       "      <td>1</td>\n",
       "      <td>68</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>176.0</td>\n",
       "      <td>168.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>23.14</td>\n",
       "      <td>60.0</td>\n",
       "      <td>79.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4233</th>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>313.0</td>\n",
       "      <td>179.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>25.97</td>\n",
       "      <td>66.0</td>\n",
       "      <td>86.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4234</th>\n",
       "      <td>1</td>\n",
       "      <td>51</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>43.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>207.0</td>\n",
       "      <td>126.5</td>\n",
       "      <td>80.0</td>\n",
       "      <td>19.71</td>\n",
       "      <td>65.0</td>\n",
       "      <td>68.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4237</th>\n",
       "      <td>0</td>\n",
       "      <td>52</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>269.0</td>\n",
       "      <td>133.5</td>\n",
       "      <td>83.0</td>\n",
       "      <td>21.47</td>\n",
       "      <td>80.0</td>\n",
       "      <td>107.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3656 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      male  age  education  currentSmoker  cigsPerDay  BPMeds  \\\n",
       "0        1   39        4.0              0         0.0     0.0   \n",
       "1        0   46        2.0              0         0.0     0.0   \n",
       "2        1   48        1.0              1        20.0     0.0   \n",
       "3        0   61        3.0              1        30.0     0.0   \n",
       "4        0   46        3.0              1        23.0     0.0   \n",
       "...    ...  ...        ...            ...         ...     ...   \n",
       "4231     1   58        3.0              0         0.0     0.0   \n",
       "4232     1   68        1.0              0         0.0     0.0   \n",
       "4233     1   50        1.0              1         1.0     0.0   \n",
       "4234     1   51        3.0              1        43.0     0.0   \n",
       "4237     0   52        2.0              0         0.0     0.0   \n",
       "\n",
       "      prevalentStroke  prevalentHyp  diabetes  totChol  sysBP  diaBP    BMI  \\\n",
       "0                   0             0         0    195.0  106.0   70.0  26.97   \n",
       "1                   0             0         0    250.0  121.0   81.0  28.73   \n",
       "2                   0             0         0    245.0  127.5   80.0  25.34   \n",
       "3                   0             1         0    225.0  150.0   95.0  28.58   \n",
       "4                   0             0         0    285.0  130.0   84.0  23.10   \n",
       "...               ...           ...       ...      ...    ...    ...    ...   \n",
       "4231                0             1         0    187.0  141.0   81.0  24.96   \n",
       "4232                0             1         0    176.0  168.0   97.0  23.14   \n",
       "4233                0             1         0    313.0  179.0   92.0  25.97   \n",
       "4234                0             0         0    207.0  126.5   80.0  19.71   \n",
       "4237                0             0         0    269.0  133.5   83.0  21.47   \n",
       "\n",
       "      heartRate  glucose  \n",
       "0          80.0     77.0  \n",
       "1          95.0     76.0  \n",
       "2          75.0     70.0  \n",
       "3          65.0    103.0  \n",
       "4          85.0     85.0  \n",
       "...         ...      ...  \n",
       "4231       80.0     81.0  \n",
       "4232       60.0     79.0  \n",
       "4233       66.0     86.0  \n",
       "4234       65.0     68.0  \n",
       "4237       80.0    107.0  \n",
       "\n",
       "[3656 rows x 15 columns]"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df_dropped[df_dropped.columns[:-1]]\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       0\n",
       "1       0\n",
       "2       0\n",
       "3       1\n",
       "4       0\n",
       "       ..\n",
       "4231    0\n",
       "4232    1\n",
       "4233    1\n",
       "4234    0\n",
       "4237    0\n",
       "Name: TenYearCHD, Length: 3656, dtype: int64"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = df_dropped[df_dropped.columns[-1]]\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a pipeline with model parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;standardscaler&#x27;, StandardScaler()),\n",
       "                (&#x27;logisticregression&#x27;, LogisticRegression())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;standardscaler&#x27;, StandardScaler()),\n",
       "                (&#x27;logisticregression&#x27;, LogisticRegression())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('standardscaler', StandardScaler()),\n",
       "                ('logisticregression', LogisticRegression())])"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import cross_val_score, RepeatedStratifiedKFold\n",
    "\n",
    "\n",
    "pipe=make_pipeline(StandardScaler(),LogisticRegression())\n",
    "pipe.fit(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a RepeatedStratifiedKFold with 10 splits and 3 repeats and random_state=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create RepeatedStratifiedKFold with 10 splits, 3 repeats, and random_state=1\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Call cross_val_score with pipeline, X, y, accuracy metric and cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores: [0.85245902 0.86065574 0.85245902 0.8579235  0.84972678 0.8442623\n",
      " 0.85205479 0.8739726  0.84931507 0.85479452 0.86612022 0.84972678\n",
      " 0.8579235  0.8442623  0.8442623  0.84699454 0.85753425 0.84931507\n",
      " 0.85479452 0.84931507 0.85245902 0.86065574 0.85245902 0.84153005\n",
      " 0.87431694 0.84699454 0.85479452 0.84931507 0.85753425 0.84383562]\n",
      "Mean Accuracy: 0.8533922199765451\n",
      "Standard Deviation: 0.007901044653733329\n",
      "a mean accuracy of 85.34% indicates that your logistic regression model is performing well on average, and the low standard deviation suggests that the performance consistency across different folds is reasonably stable.\n"
     ]
    }
   ],
   "source": [
    "# Call cross_val_score with pipeline, X, y, accuracy metric, and cv\n",
    "accuracy_scores = cross_val_score(pipe, X, y, scoring='accuracy', cv=cv)\n",
    "print(f'Scores: {accuracy_scores}')\n",
    "# Print the mean accuracy and standard deviation\n",
    "print(f'Mean Accuracy: {accuracy_scores.mean()}')\n",
    "print(f'Standard Deviation: {accuracy_scores.std()}')\n",
    "print(\"a mean accuracy of 85.34% indicates that your logistic regression model is performing well on average, and the low standard deviation suggests that the performance consistency across different folds is reasonably stable.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print the Mean Accuracy and Standard Deviation from scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy: 0.848  | Std: 0.006\n"
     ]
    }
   ],
   "source": [
    "print(f\"Mean Accuracy: {round(np.mean(scores), 3)}  | Std: {round(np.std(scores), 3)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean Accuracy: 0.848  | Std: 0.006 When dropping rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build a Logistic Regression model with SimpleImputer Mean Strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold, cross_val_score\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>male</th>\n",
       "      <th>age</th>\n",
       "      <th>education</th>\n",
       "      <th>currentSmoker</th>\n",
       "      <th>cigsPerDay</th>\n",
       "      <th>BPMeds</th>\n",
       "      <th>prevalentStroke</th>\n",
       "      <th>prevalentHyp</th>\n",
       "      <th>diabetes</th>\n",
       "      <th>totChol</th>\n",
       "      <th>sysBP</th>\n",
       "      <th>diaBP</th>\n",
       "      <th>BMI</th>\n",
       "      <th>heartRate</th>\n",
       "      <th>glucose</th>\n",
       "      <th>TenYearCHD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>26.97</td>\n",
       "      <td>80.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>28.73</td>\n",
       "      <td>95.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>48</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>127.5</td>\n",
       "      <td>80.0</td>\n",
       "      <td>25.34</td>\n",
       "      <td>75.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>61</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>225.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>28.58</td>\n",
       "      <td>65.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>285.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>23.10</td>\n",
       "      <td>85.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4233</th>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>313.0</td>\n",
       "      <td>179.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>25.97</td>\n",
       "      <td>66.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4234</th>\n",
       "      <td>1</td>\n",
       "      <td>51</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>43.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>207.0</td>\n",
       "      <td>126.5</td>\n",
       "      <td>80.0</td>\n",
       "      <td>19.71</td>\n",
       "      <td>65.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4235</th>\n",
       "      <td>0</td>\n",
       "      <td>48</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>20.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>248.0</td>\n",
       "      <td>131.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>22.00</td>\n",
       "      <td>84.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4236</th>\n",
       "      <td>0</td>\n",
       "      <td>44</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>210.0</td>\n",
       "      <td>126.5</td>\n",
       "      <td>87.0</td>\n",
       "      <td>19.16</td>\n",
       "      <td>86.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4237</th>\n",
       "      <td>0</td>\n",
       "      <td>52</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>269.0</td>\n",
       "      <td>133.5</td>\n",
       "      <td>83.0</td>\n",
       "      <td>21.47</td>\n",
       "      <td>80.0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4238 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      male  age  education  currentSmoker  cigsPerDay  BPMeds  \\\n",
       "0        1   39        4.0              0         0.0     0.0   \n",
       "1        0   46        2.0              0         0.0     0.0   \n",
       "2        1   48        1.0              1        20.0     0.0   \n",
       "3        0   61        3.0              1        30.0     0.0   \n",
       "4        0   46        3.0              1        23.0     0.0   \n",
       "...    ...  ...        ...            ...         ...     ...   \n",
       "4233     1   50        1.0              1         1.0     0.0   \n",
       "4234     1   51        3.0              1        43.0     0.0   \n",
       "4235     0   48        2.0              1        20.0     NaN   \n",
       "4236     0   44        1.0              1        15.0     0.0   \n",
       "4237     0   52        2.0              0         0.0     0.0   \n",
       "\n",
       "      prevalentStroke  prevalentHyp  diabetes  totChol  sysBP  diaBP    BMI  \\\n",
       "0                   0             0         0    195.0  106.0   70.0  26.97   \n",
       "1                   0             0         0    250.0  121.0   81.0  28.73   \n",
       "2                   0             0         0    245.0  127.5   80.0  25.34   \n",
       "3                   0             1         0    225.0  150.0   95.0  28.58   \n",
       "4                   0             0         0    285.0  130.0   84.0  23.10   \n",
       "...               ...           ...       ...      ...    ...    ...    ...   \n",
       "4233                0             1         0    313.0  179.0   92.0  25.97   \n",
       "4234                0             0         0    207.0  126.5   80.0  19.71   \n",
       "4235                0             0         0    248.0  131.0   72.0  22.00   \n",
       "4236                0             0         0    210.0  126.5   87.0  19.16   \n",
       "4237                0             0         0    269.0  133.5   83.0  21.47   \n",
       "\n",
       "      heartRate  glucose  TenYearCHD  \n",
       "0          80.0     77.0           0  \n",
       "1          95.0     76.0           0  \n",
       "2          75.0     70.0           0  \n",
       "3          65.0    103.0           1  \n",
       "4          85.0     85.0           0  \n",
       "...         ...      ...         ...  \n",
       "4233       66.0     86.0           1  \n",
       "4234       65.0     68.0           0  \n",
       "4235       84.0     86.0           0  \n",
       "4236       86.0      NaN           0  \n",
       "4237       80.0    107.0           0  \n",
       "\n",
       "[4238 rows x 16 columns]"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv(\"heart_disease.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split dataset into X and y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>male</th>\n",
       "      <th>age</th>\n",
       "      <th>education</th>\n",
       "      <th>currentSmoker</th>\n",
       "      <th>cigsPerDay</th>\n",
       "      <th>BPMeds</th>\n",
       "      <th>prevalentStroke</th>\n",
       "      <th>prevalentHyp</th>\n",
       "      <th>diabetes</th>\n",
       "      <th>totChol</th>\n",
       "      <th>sysBP</th>\n",
       "      <th>diaBP</th>\n",
       "      <th>BMI</th>\n",
       "      <th>heartRate</th>\n",
       "      <th>glucose</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>26.97</td>\n",
       "      <td>80.0</td>\n",
       "      <td>77.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>28.73</td>\n",
       "      <td>95.0</td>\n",
       "      <td>76.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>48</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>127.5</td>\n",
       "      <td>80.0</td>\n",
       "      <td>25.34</td>\n",
       "      <td>75.0</td>\n",
       "      <td>70.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>61</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>225.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>28.58</td>\n",
       "      <td>65.0</td>\n",
       "      <td>103.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>285.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>23.10</td>\n",
       "      <td>85.0</td>\n",
       "      <td>85.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4233</th>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>313.0</td>\n",
       "      <td>179.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>25.97</td>\n",
       "      <td>66.0</td>\n",
       "      <td>86.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4234</th>\n",
       "      <td>1</td>\n",
       "      <td>51</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>43.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>207.0</td>\n",
       "      <td>126.5</td>\n",
       "      <td>80.0</td>\n",
       "      <td>19.71</td>\n",
       "      <td>65.0</td>\n",
       "      <td>68.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4235</th>\n",
       "      <td>0</td>\n",
       "      <td>48</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>20.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>248.0</td>\n",
       "      <td>131.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>22.00</td>\n",
       "      <td>84.0</td>\n",
       "      <td>86.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4236</th>\n",
       "      <td>0</td>\n",
       "      <td>44</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>210.0</td>\n",
       "      <td>126.5</td>\n",
       "      <td>87.0</td>\n",
       "      <td>19.16</td>\n",
       "      <td>86.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4237</th>\n",
       "      <td>0</td>\n",
       "      <td>52</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>269.0</td>\n",
       "      <td>133.5</td>\n",
       "      <td>83.0</td>\n",
       "      <td>21.47</td>\n",
       "      <td>80.0</td>\n",
       "      <td>107.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4238 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      male  age  education  currentSmoker  cigsPerDay  BPMeds  \\\n",
       "0        1   39        4.0              0         0.0     0.0   \n",
       "1        0   46        2.0              0         0.0     0.0   \n",
       "2        1   48        1.0              1        20.0     0.0   \n",
       "3        0   61        3.0              1        30.0     0.0   \n",
       "4        0   46        3.0              1        23.0     0.0   \n",
       "...    ...  ...        ...            ...         ...     ...   \n",
       "4233     1   50        1.0              1         1.0     0.0   \n",
       "4234     1   51        3.0              1        43.0     0.0   \n",
       "4235     0   48        2.0              1        20.0     NaN   \n",
       "4236     0   44        1.0              1        15.0     0.0   \n",
       "4237     0   52        2.0              0         0.0     0.0   \n",
       "\n",
       "      prevalentStroke  prevalentHyp  diabetes  totChol  sysBP  diaBP    BMI  \\\n",
       "0                   0             0         0    195.0  106.0   70.0  26.97   \n",
       "1                   0             0         0    250.0  121.0   81.0  28.73   \n",
       "2                   0             0         0    245.0  127.5   80.0  25.34   \n",
       "3                   0             1         0    225.0  150.0   95.0  28.58   \n",
       "4                   0             0         0    285.0  130.0   84.0  23.10   \n",
       "...               ...           ...       ...      ...    ...    ...    ...   \n",
       "4233                0             1         0    313.0  179.0   92.0  25.97   \n",
       "4234                0             0         0    207.0  126.5   80.0  19.71   \n",
       "4235                0             0         0    248.0  131.0   72.0  22.00   \n",
       "4236                0             0         0    210.0  126.5   87.0  19.16   \n",
       "4237                0             0         0    269.0  133.5   83.0  21.47   \n",
       "\n",
       "      heartRate  glucose  \n",
       "0          80.0     77.0  \n",
       "1          95.0     76.0  \n",
       "2          75.0     70.0  \n",
       "3          65.0    103.0  \n",
       "4          85.0     85.0  \n",
       "...         ...      ...  \n",
       "4233       66.0     86.0  \n",
       "4234       65.0     68.0  \n",
       "4235       84.0     86.0  \n",
       "4236       86.0      NaN  \n",
       "4237       80.0    107.0  \n",
       "\n",
       "[4238 rows x 15 columns]"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape\n",
    "# Separate features (X) and target (y)\n",
    "X = df[df.columns[:-1]]\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       0\n",
       "1       0\n",
       "2       0\n",
       "3       1\n",
       "4       0\n",
       "       ..\n",
       "4233    1\n",
       "4234    0\n",
       "4235    0\n",
       "4236    0\n",
       "4237    0\n",
       "Name: TenYearCHD, Length: 4238, dtype: int64"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = df[df.columns[-1]]\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a SimpleImputer with mean strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a pipeline with SimpleImputer and StandardScaler for preprocessing\n",
    "preprocessing_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='mean')),  # Example: Using mean strategy for imputation\n",
    "    ('scaler', StandardScaler())\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a Logistic Regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Logistic Regression model\n",
    "model = LogisticRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a pipeline with impute and model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_pipeline = Pipeline([\n",
    "    ('preprocessing', preprocessing_pipeline),\n",
    "    ('model', model)\n",
    "])\n",
    "# Fit the final pipeline with the entire dataset\n",
    "pipeline_1=final_pipeline.fit(X, y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a RepeatedStratifiedKFold with 10 splits and 3 repeats and random_state=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Call cross_val_score with pipeline, X, y, accuracy metric and cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_val_score(pipeline_1, X, y, scoring='accuracy', cv=cv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.8490566 , 0.85377358, 0.84669811, 0.8490566 , 0.84433962,\n",
       "       0.84669811, 0.84669811, 0.8490566 , 0.84869976, 0.85106383,\n",
       "       0.8490566 , 0.85377358, 0.85141509, 0.85613208, 0.84669811,\n",
       "       0.85141509, 0.84433962, 0.8490566 , 0.8534279 , 0.8534279 ,\n",
       "       0.85141509, 0.85141509, 0.8490566 , 0.84433962, 0.85141509,\n",
       "       0.85141509, 0.85141509, 0.85613208, 0.84869976, 0.8463357 ])"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print the Mean Accuracy and Standard Deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy: 0.8545720148088674\n",
      "Standard Deviation: 0.005801512841800946\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Print the Mean Accuracy and Standard Deviation\n",
    "mean_accuracy = scores.mean()\n",
    "std_deviation = scores.std()\n",
    "\n",
    "print(f\"Mean Accuracy: {mean_accuracy}\")\n",
    "print(f\"Standard Deviation: {std_deviation}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Which accuracy is better? \n",
    "- Dropping missing values\n",
    "- SimpleImputer with Mean Strategy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### By using Standard Scaler accuracy improved from 84.9% to 85.4% with simple impute mean stratergy. Although Standard deviation increased by 0.2%. \n",
    "### Droping: 84.6% vs SImpute: 85.4%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SimpleImputer Mean - Benchmark after Mean imputation with RandomForest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold, cross_val_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a SimpleImputer with mean strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load your dataset\n",
    "df = pd.read_csv(\"heart_disease.csv\")\n",
    "\n",
    "# Separate features (X) and target (y)\n",
    "X = df[df.columns[:-1]]\n",
    "y = df[df.columns[-1]]\n",
    "\n",
    "# Create a SimpleImputer with mean strategy\n",
    "imputer = SimpleImputer(strategy='mean')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a RandomForest model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a RandomForest model\n",
    "rf_model = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a pipeline with imputer, StandardScaler, and RandomForest\n",
    "pipeline = Pipeline([\n",
    "    ('imputer', imputer),\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('rf', rf_model)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create RepeatedStratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create RepeatedStratifiedKFold\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Cross_val_score\n",
    "scores = cross_val_score(pipeline, X, y, scoring='accuracy', cv=cv)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print Mean Accuracy and Standard Deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy: 0.8474155106531661\n",
      "Standard Deviation: 0.006964572528087078\n"
     ]
    }
   ],
   "source": [
    "# Print Mean Accuracy and Standard Deviation\n",
    "print(f\"Mean Accuracy: {scores.mean()}\")\n",
    "print(f\"Standard Deviation: {scores.std()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment\n",
    "# Run experiments with different Strategies and different algorithms\n",
    "\n",
    "## STRATEGIES\n",
    "- Mean\n",
    "- Median\n",
    "- Most_frequent\n",
    "- Constant\n",
    "\n",
    "## ALGORITHMS\n",
    "- Logistic Regression\n",
    "- KNN\n",
    "- Random Forest\n",
    "- SVM\n",
    "- Any other algorithm of your choice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hint: Collect the pipeline creation, KFold, and Cross_Val_Score inside a for loop and iterate over different strategies in a list and different algorithms in a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Strategy: mean, Algorithm: Logistic Regression\n",
      "Mean Accuracy: 0.8545720148088674\n",
      "Standard Deviation: 0.005801512841800946\n",
      "\n",
      "==============================\n",
      "\n",
      "Strategy: mean, Algorithm: KNN\n",
      "Mean Accuracy: 0.8339650519648512\n",
      "Standard Deviation: 0.00885273925919613\n",
      "\n",
      "==============================\n",
      "\n",
      "Strategy: mean, Algorithm: Random Forest\n",
      "Mean Accuracy: 0.8501672688344707\n",
      "Standard Deviation: 0.005844029053273887\n",
      "\n",
      "==============================\n",
      "\n",
      "Strategy: mean, Algorithm: SVM\n",
      "Mean Accuracy: 0.848200373195355\n",
      "Standard Deviation: 0.003706964775994121\n",
      "\n",
      "==============================\n",
      "\n",
      "Strategy: median, Algorithm: Logistic Regression\n",
      "Mean Accuracy: 0.8545720148088674\n",
      "Standard Deviation: 0.005801512841800946\n",
      "\n",
      "==============================\n",
      "\n",
      "Strategy: median, Algorithm: KNN\n",
      "Mean Accuracy: 0.8345155522845205\n",
      "Standard Deviation: 0.009149983683132011\n",
      "\n",
      "==============================\n",
      "\n",
      "Strategy: median, Algorithm: Random Forest\n",
      "Mean Accuracy: 0.8487519886405877\n",
      "Standard Deviation: 0.006981342642307474\n",
      "\n",
      "==============================\n",
      "\n",
      "Strategy: median, Algorithm: SVM\n",
      "Mean Accuracy: 0.848200373195355\n",
      "Standard Deviation: 0.003706964775994121\n",
      "\n",
      "==============================\n",
      "\n",
      "Strategy: most_frequent, Algorithm: Logistic Regression\n",
      "Mean Accuracy: 0.8547294333675303\n",
      "Standard Deviation: 0.005773326746193872\n",
      "\n",
      "==============================\n",
      "\n",
      "Strategy: most_frequent, Algorithm: KNN\n",
      "Mean Accuracy: 0.8345159239930414\n",
      "Standard Deviation: 0.008336294954155811\n",
      "\n",
      "==============================\n",
      "\n",
      "Strategy: most_frequent, Algorithm: Random Forest\n",
      "Mean Accuracy: 0.8504047905794193\n",
      "Standard Deviation: 0.006803755713815679\n",
      "\n",
      "==============================\n",
      "\n",
      "Strategy: most_frequent, Algorithm: SVM\n",
      "Mean Accuracy: 0.8481217568431538\n",
      "Standard Deviation: 0.003712976675825406\n",
      "\n",
      "==============================\n",
      "\n",
      "Strategy: constant, Algorithm: Logistic Regression\n",
      "Mean Accuracy: 0.853706305663351\n",
      "Standard Deviation: 0.005733278655843713\n",
      "\n",
      "==============================\n",
      "\n",
      "Strategy: constant, Algorithm: KNN\n",
      "Mean Accuracy: 0.8335723419123661\n",
      "Standard Deviation: 0.007966686233080588\n",
      "\n",
      "==============================\n",
      "\n",
      "Strategy: constant, Algorithm: Random Forest\n",
      "Mean Accuracy: 0.8492236867537951\n",
      "Standard Deviation: 0.004813077401496039\n",
      "\n",
      "==============================\n",
      "\n",
      "Strategy: constant, Algorithm: SVM\n",
      "Mean Accuracy: 0.8458411392122752\n",
      "Standard Deviation: 0.003838845503372653\n",
      "\n",
      "==============================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold, cross_val_score\n",
    "\n",
    "# Load your dataset\n",
    "df = pd.read_csv(\"heart_disease.csv\")\n",
    "\n",
    "# Separate features (X) and target (y)\n",
    "X = df[df.columns[:-1]]\n",
    "y = df[df.columns[-1]]\n",
    "\n",
    "# Define strategies and algorithms\n",
    "strategies = ['mean', 'median', 'most_frequent', 'constant']\n",
    "algorithms = [\n",
    "    ('Logistic Regression', LogisticRegression()),\n",
    "    ('KNN', KNeighborsClassifier()),\n",
    "    ('Random Forest', RandomForestClassifier()),\n",
    "    ('SVM', SVC())\n",
    "    # Add any other algorithms of your choice\n",
    "]\n",
    "\n",
    "# Iterate over strategies and algorithms\n",
    "for strategy in strategies:\n",
    "    for algo_name, algo_model in algorithms:\n",
    "        # Create a SimpleImputer with the current strategy\n",
    "        imputer = SimpleImputer(strategy=strategy)\n",
    "\n",
    "        # Create a pipeline with imputer, StandardScaler, and the current algorithm\n",
    "        pipeline = Pipeline([\n",
    "            ('imputer', imputer),\n",
    "            ('scaler', StandardScaler()),\n",
    "            ('model', algo_model)\n",
    "        ])\n",
    "\n",
    "        # Create RepeatedStratifiedKFold\n",
    "        cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "\n",
    "        # Create Cross_val_score\n",
    "        scores = cross_val_score(pipeline, X, y, scoring='accuracy', cv=cv)\n",
    "\n",
    "        # Print results\n",
    "        print(f\"Strategy: {strategy}, Algorithm: {algo_name}\")\n",
    "        print(f\"Mean Accuracy: {scores.mean()}\")\n",
    "        print(f\"Standard Deviation: {scores.std()}\")\n",
    "        print(\"\\n\" + \"=\"*30 + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 580, number of negative: 3234\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001062 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1019\n",
      "[LightGBM] [Info] Number of data points in the train set: 3814, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.152071 -> initscore=-1.718447\n",
      "[LightGBM] [Info] Start training from score -1.718447\n",
      "[LightGBM] [Info] Number of positive: 580, number of negative: 3234\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000644 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1021\n",
      "[LightGBM] [Info] Number of data points in the train set: 3814, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.152071 -> initscore=-1.718447\n",
      "[LightGBM] [Info] Start training from score -1.718447\n",
      "[LightGBM] [Info] Number of positive: 580, number of negative: 3234\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000410 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1026\n",
      "[LightGBM] [Info] Number of data points in the train set: 3814, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.152071 -> initscore=-1.718447\n",
      "[LightGBM] [Info] Start training from score -1.718447\n",
      "[LightGBM] [Info] Number of positive: 580, number of negative: 3234\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000453 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1023\n",
      "[LightGBM] [Info] Number of data points in the train set: 3814, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.152071 -> initscore=-1.718447\n",
      "[LightGBM] [Info] Start training from score -1.718447\n",
      "[LightGBM] [Info] Number of positive: 579, number of negative: 3235\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000677 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1027\n",
      "[LightGBM] [Info] Number of data points in the train set: 3814, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.151809 -> initscore=-1.720482\n",
      "[LightGBM] [Info] Start training from score -1.720482\n",
      "[LightGBM] [Info] Number of positive: 579, number of negative: 3235\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000591 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1022\n",
      "[LightGBM] [Info] Number of data points in the train set: 3814, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.151809 -> initscore=-1.720482\n",
      "[LightGBM] [Info] Start training from score -1.720482\n",
      "[LightGBM] [Info] Number of positive: 579, number of negative: 3235\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000422 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1019\n",
      "[LightGBM] [Info] Number of data points in the train set: 3814, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.151809 -> initscore=-1.720482\n",
      "[LightGBM] [Info] Start training from score -1.720482\n",
      "[LightGBM] [Info] Number of positive: 579, number of negative: 3235\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000428 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1023\n",
      "[LightGBM] [Info] Number of data points in the train set: 3814, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.151809 -> initscore=-1.720482\n",
      "[LightGBM] [Info] Start training from score -1.720482\n",
      "[LightGBM] [Info] Number of positive: 580, number of negative: 3235\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000414 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1022\n",
      "[LightGBM] [Info] Number of data points in the train set: 3815, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.152031 -> initscore=-1.718756\n",
      "[LightGBM] [Info] Start training from score -1.718756\n",
      "[LightGBM] [Info] Number of positive: 580, number of negative: 3235\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000539 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1026\n",
      "[LightGBM] [Info] Number of data points in the train set: 3815, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.152031 -> initscore=-1.718756\n",
      "[LightGBM] [Info] Start training from score -1.718756\n",
      "[LightGBM] [Info] Number of positive: 580, number of negative: 3234\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000526 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1025\n",
      "[LightGBM] [Info] Number of data points in the train set: 3814, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.152071 -> initscore=-1.718447\n",
      "[LightGBM] [Info] Start training from score -1.718447\n",
      "[LightGBM] [Info] Number of positive: 580, number of negative: 3234\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000365 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1019\n",
      "[LightGBM] [Info] Number of data points in the train set: 3814, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.152071 -> initscore=-1.718447\n",
      "[LightGBM] [Info] Start training from score -1.718447\n",
      "[LightGBM] [Info] Number of positive: 580, number of negative: 3234\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000342 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1028\n",
      "[LightGBM] [Info] Number of data points in the train set: 3814, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.152071 -> initscore=-1.718447\n",
      "[LightGBM] [Info] Start training from score -1.718447\n",
      "[LightGBM] [Info] Number of positive: 580, number of negative: 3234\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000513 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1027\n",
      "[LightGBM] [Info] Number of data points in the train set: 3814, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.152071 -> initscore=-1.718447\n",
      "[LightGBM] [Info] Start training from score -1.718447\n",
      "[LightGBM] [Info] Number of positive: 579, number of negative: 3235\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000475 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1024\n",
      "[LightGBM] [Info] Number of data points in the train set: 3814, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.151809 -> initscore=-1.720482\n",
      "[LightGBM] [Info] Start training from score -1.720482\n",
      "[LightGBM] [Info] Number of positive: 579, number of negative: 3235\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000439 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1024\n",
      "[LightGBM] [Info] Number of data points in the train set: 3814, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.151809 -> initscore=-1.720482\n",
      "[LightGBM] [Info] Start training from score -1.720482\n",
      "[LightGBM] [Info] Number of positive: 579, number of negative: 3235\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000431 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1017\n",
      "[LightGBM] [Info] Number of data points in the train set: 3814, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.151809 -> initscore=-1.720482\n",
      "[LightGBM] [Info] Start training from score -1.720482\n",
      "[LightGBM] [Info] Number of positive: 579, number of negative: 3235\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000467 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1021\n",
      "[LightGBM] [Info] Number of data points in the train set: 3814, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.151809 -> initscore=-1.720482\n",
      "[LightGBM] [Info] Start training from score -1.720482\n",
      "[LightGBM] [Info] Number of positive: 580, number of negative: 3235\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000379 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1029\n",
      "[LightGBM] [Info] Number of data points in the train set: 3815, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.152031 -> initscore=-1.718756\n",
      "[LightGBM] [Info] Start training from score -1.718756\n",
      "[LightGBM] [Info] Number of positive: 580, number of negative: 3235\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000392 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1019\n",
      "[LightGBM] [Info] Number of data points in the train set: 3815, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.152031 -> initscore=-1.718756\n",
      "[LightGBM] [Info] Start training from score -1.718756\n",
      "[LightGBM] [Info] Number of positive: 580, number of negative: 3234\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000450 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1023\n",
      "[LightGBM] [Info] Number of data points in the train set: 3814, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.152071 -> initscore=-1.718447\n",
      "[LightGBM] [Info] Start training from score -1.718447\n",
      "[LightGBM] [Info] Number of positive: 580, number of negative: 3234\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000427 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1025\n",
      "[LightGBM] [Info] Number of data points in the train set: 3814, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.152071 -> initscore=-1.718447\n",
      "[LightGBM] [Info] Start training from score -1.718447\n",
      "[LightGBM] [Info] Number of positive: 580, number of negative: 3234\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000390 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1026\n",
      "[LightGBM] [Info] Number of data points in the train set: 3814, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.152071 -> initscore=-1.718447\n",
      "[LightGBM] [Info] Start training from score -1.718447\n",
      "[LightGBM] [Info] Number of positive: 580, number of negative: 3234\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000404 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1028\n",
      "[LightGBM] [Info] Number of data points in the train set: 3814, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.152071 -> initscore=-1.718447\n",
      "[LightGBM] [Info] Start training from score -1.718447\n",
      "[LightGBM] [Info] Number of positive: 579, number of negative: 3235\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000370 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1023\n",
      "[LightGBM] [Info] Number of data points in the train set: 3814, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.151809 -> initscore=-1.720482\n",
      "[LightGBM] [Info] Start training from score -1.720482\n",
      "[LightGBM] [Info] Number of positive: 579, number of negative: 3235\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000337 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1028\n",
      "[LightGBM] [Info] Number of data points in the train set: 3814, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.151809 -> initscore=-1.720482\n",
      "[LightGBM] [Info] Start training from score -1.720482\n",
      "[LightGBM] [Info] Number of positive: 579, number of negative: 3235\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000377 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1020\n",
      "[LightGBM] [Info] Number of data points in the train set: 3814, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.151809 -> initscore=-1.720482\n",
      "[LightGBM] [Info] Start training from score -1.720482\n",
      "[LightGBM] [Info] Number of positive: 579, number of negative: 3235\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000405 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1016\n",
      "[LightGBM] [Info] Number of data points in the train set: 3814, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.151809 -> initscore=-1.720482\n",
      "[LightGBM] [Info] Start training from score -1.720482\n",
      "[LightGBM] [Info] Number of positive: 580, number of negative: 3235\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000396 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1023\n",
      "[LightGBM] [Info] Number of data points in the train set: 3815, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.152031 -> initscore=-1.718756\n",
      "[LightGBM] [Info] Start training from score -1.718756\n",
      "[LightGBM] [Info] Number of positive: 580, number of negative: 3235\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000400 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1026\n",
      "[LightGBM] [Info] Number of data points in the train set: 3815, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.152031 -> initscore=-1.718756\n",
      "[LightGBM] [Info] Start training from score -1.718756\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\macwa\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "C:\\Users\\macwa\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "C:\\Users\\macwa\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "C:\\Users\\macwa\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "C:\\Users\\macwa\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "C:\\Users\\macwa\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "C:\\Users\\macwa\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "C:\\Users\\macwa\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "C:\\Users\\macwa\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "C:\\Users\\macwa\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "C:\\Users\\macwa\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "C:\\Users\\macwa\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "C:\\Users\\macwa\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "C:\\Users\\macwa\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "C:\\Users\\macwa\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "C:\\Users\\macwa\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "C:\\Users\\macwa\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "C:\\Users\\macwa\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "C:\\Users\\macwa\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "C:\\Users\\macwa\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "C:\\Users\\macwa\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "C:\\Users\\macwa\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "C:\\Users\\macwa\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "C:\\Users\\macwa\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "C:\\Users\\macwa\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "C:\\Users\\macwa\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "C:\\Users\\macwa\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "C:\\Users\\macwa\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "C:\\Users\\macwa\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "C:\\Users\\macwa\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 580, number of negative: 3234\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000389 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1017\n",
      "[LightGBM] [Info] Number of data points in the train set: 3814, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.152071 -> initscore=-1.718447\n",
      "[LightGBM] [Info] Start training from score -1.718447\n",
      "[LightGBM] [Info] Number of positive: 580, number of negative: 3234\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000507 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1018\n",
      "[LightGBM] [Info] Number of data points in the train set: 3814, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.152071 -> initscore=-1.718447\n",
      "[LightGBM] [Info] Start training from score -1.718447\n",
      "[LightGBM] [Info] Number of positive: 580, number of negative: 3234\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000432 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1025\n",
      "[LightGBM] [Info] Number of data points in the train set: 3814, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.152071 -> initscore=-1.718447\n",
      "[LightGBM] [Info] Start training from score -1.718447\n",
      "[LightGBM] [Info] Number of positive: 580, number of negative: 3234\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000428 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1021\n",
      "[LightGBM] [Info] Number of data points in the train set: 3814, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.152071 -> initscore=-1.718447\n",
      "[LightGBM] [Info] Start training from score -1.718447\n",
      "[LightGBM] [Info] Number of positive: 579, number of negative: 3235\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000486 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1026\n",
      "[LightGBM] [Info] Number of data points in the train set: 3814, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.151809 -> initscore=-1.720482\n",
      "[LightGBM] [Info] Start training from score -1.720482\n",
      "[LightGBM] [Info] Number of positive: 579, number of negative: 3235\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000439 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1019\n",
      "[LightGBM] [Info] Number of data points in the train set: 3814, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.151809 -> initscore=-1.720482\n",
      "[LightGBM] [Info] Start training from score -1.720482\n",
      "[LightGBM] [Info] Number of positive: 579, number of negative: 3235\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000496 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1017\n",
      "[LightGBM] [Info] Number of data points in the train set: 3814, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.151809 -> initscore=-1.720482\n",
      "[LightGBM] [Info] Start training from score -1.720482\n",
      "[LightGBM] [Info] Number of positive: 579, number of negative: 3235\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000428 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1021\n",
      "[LightGBM] [Info] Number of data points in the train set: 3814, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.151809 -> initscore=-1.720482\n",
      "[LightGBM] [Info] Start training from score -1.720482\n",
      "[LightGBM] [Info] Number of positive: 580, number of negative: 3235\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000417 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1018\n",
      "[LightGBM] [Info] Number of data points in the train set: 3815, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.152031 -> initscore=-1.718756\n",
      "[LightGBM] [Info] Start training from score -1.718756\n",
      "[LightGBM] [Info] Number of positive: 580, number of negative: 3235\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000372 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1023\n",
      "[LightGBM] [Info] Number of data points in the train set: 3815, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.152031 -> initscore=-1.718756\n",
      "[LightGBM] [Info] Start training from score -1.718756\n",
      "[LightGBM] [Info] Number of positive: 580, number of negative: 3234\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000386 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1022\n",
      "[LightGBM] [Info] Number of data points in the train set: 3814, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.152071 -> initscore=-1.718447\n",
      "[LightGBM] [Info] Start training from score -1.718447\n",
      "[LightGBM] [Info] Number of positive: 580, number of negative: 3234\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000413 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1018\n",
      "[LightGBM] [Info] Number of data points in the train set: 3814, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.152071 -> initscore=-1.718447\n",
      "[LightGBM] [Info] Start training from score -1.718447\n",
      "[LightGBM] [Info] Number of positive: 580, number of negative: 3234\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000423 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1024\n",
      "[LightGBM] [Info] Number of data points in the train set: 3814, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.152071 -> initscore=-1.718447\n",
      "[LightGBM] [Info] Start training from score -1.718447\n",
      "[LightGBM] [Info] Number of positive: 580, number of negative: 3234\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000325 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1025\n",
      "[LightGBM] [Info] Number of data points in the train set: 3814, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.152071 -> initscore=-1.718447\n",
      "[LightGBM] [Info] Start training from score -1.718447\n",
      "[LightGBM] [Info] Number of positive: 579, number of negative: 3235\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000375 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1019\n",
      "[LightGBM] [Info] Number of data points in the train set: 3814, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.151809 -> initscore=-1.720482\n",
      "[LightGBM] [Info] Start training from score -1.720482\n",
      "[LightGBM] [Info] Number of positive: 579, number of negative: 3235\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000336 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1022\n",
      "[LightGBM] [Info] Number of data points in the train set: 3814, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.151809 -> initscore=-1.720482\n",
      "[LightGBM] [Info] Start training from score -1.720482\n",
      "[LightGBM] [Info] Number of positive: 579, number of negative: 3235\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000383 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1015\n",
      "[LightGBM] [Info] Number of data points in the train set: 3814, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.151809 -> initscore=-1.720482\n",
      "[LightGBM] [Info] Start training from score -1.720482\n",
      "[LightGBM] [Info] Number of positive: 579, number of negative: 3235\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000550 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1018\n",
      "[LightGBM] [Info] Number of data points in the train set: 3814, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.151809 -> initscore=-1.720482\n",
      "[LightGBM] [Info] Start training from score -1.720482\n",
      "[LightGBM] [Info] Number of positive: 580, number of negative: 3235\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000478 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1026\n",
      "[LightGBM] [Info] Number of data points in the train set: 3815, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.152031 -> initscore=-1.718756\n",
      "[LightGBM] [Info] Start training from score -1.718756\n",
      "[LightGBM] [Info] Number of positive: 580, number of negative: 3235\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000465 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1017\n",
      "[LightGBM] [Info] Number of data points in the train set: 3815, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.152031 -> initscore=-1.718756\n",
      "[LightGBM] [Info] Start training from score -1.718756\n",
      "[LightGBM] [Info] Number of positive: 580, number of negative: 3234\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000432 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1019\n",
      "[LightGBM] [Info] Number of data points in the train set: 3814, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.152071 -> initscore=-1.718447\n",
      "[LightGBM] [Info] Start training from score -1.718447\n",
      "[LightGBM] [Info] Number of positive: 580, number of negative: 3234\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000380 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1023\n",
      "[LightGBM] [Info] Number of data points in the train set: 3814, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.152071 -> initscore=-1.718447\n",
      "[LightGBM] [Info] Start training from score -1.718447\n",
      "[LightGBM] [Info] Number of positive: 580, number of negative: 3234\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000447 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1023\n",
      "[LightGBM] [Info] Number of data points in the train set: 3814, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.152071 -> initscore=-1.718447\n",
      "[LightGBM] [Info] Start training from score -1.718447\n",
      "[LightGBM] [Info] Number of positive: 580, number of negative: 3234\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000472 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1027\n",
      "[LightGBM] [Info] Number of data points in the train set: 3814, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.152071 -> initscore=-1.718447\n",
      "[LightGBM] [Info] Start training from score -1.718447\n",
      "[LightGBM] [Info] Number of positive: 579, number of negative: 3235\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000518 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1020\n",
      "[LightGBM] [Info] Number of data points in the train set: 3814, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.151809 -> initscore=-1.720482\n",
      "[LightGBM] [Info] Start training from score -1.720482\n",
      "[LightGBM] [Info] Number of positive: 579, number of negative: 3235\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000409 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1022\n",
      "[LightGBM] [Info] Number of data points in the train set: 3814, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.151809 -> initscore=-1.720482\n",
      "[LightGBM] [Info] Start training from score -1.720482\n",
      "[LightGBM] [Info] Number of positive: 579, number of negative: 3235\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000500 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1019\n",
      "[LightGBM] [Info] Number of data points in the train set: 3814, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.151809 -> initscore=-1.720482\n",
      "[LightGBM] [Info] Start training from score -1.720482\n",
      "[LightGBM] [Info] Number of positive: 579, number of negative: 3235\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000397 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1015\n",
      "[LightGBM] [Info] Number of data points in the train set: 3814, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.151809 -> initscore=-1.720482\n",
      "[LightGBM] [Info] Start training from score -1.720482\n",
      "[LightGBM] [Info] Number of positive: 580, number of negative: 3235\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000422 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1020\n",
      "[LightGBM] [Info] Number of data points in the train set: 3815, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.152031 -> initscore=-1.718756\n",
      "[LightGBM] [Info] Start training from score -1.718756\n",
      "[LightGBM] [Info] Number of positive: 580, number of negative: 3235\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000440 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1024\n",
      "[LightGBM] [Info] Number of data points in the train set: 3815, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.152031 -> initscore=-1.718756\n",
      "[LightGBM] [Info] Start training from score -1.718756\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\macwa\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "C:\\Users\\macwa\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "C:\\Users\\macwa\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "C:\\Users\\macwa\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "C:\\Users\\macwa\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "C:\\Users\\macwa\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "C:\\Users\\macwa\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "C:\\Users\\macwa\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "C:\\Users\\macwa\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "C:\\Users\\macwa\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "C:\\Users\\macwa\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "C:\\Users\\macwa\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "C:\\Users\\macwa\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "C:\\Users\\macwa\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "C:\\Users\\macwa\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "C:\\Users\\macwa\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "C:\\Users\\macwa\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "C:\\Users\\macwa\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "C:\\Users\\macwa\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "C:\\Users\\macwa\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "C:\\Users\\macwa\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "C:\\Users\\macwa\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "C:\\Users\\macwa\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "C:\\Users\\macwa\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "C:\\Users\\macwa\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "C:\\Users\\macwa\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "C:\\Users\\macwa\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "C:\\Users\\macwa\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "C:\\Users\\macwa\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "C:\\Users\\macwa\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 580, number of negative: 3234\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000608 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1017\n",
      "[LightGBM] [Info] Number of data points in the train set: 3814, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.152071 -> initscore=-1.718447\n",
      "[LightGBM] [Info] Start training from score -1.718447\n",
      "[LightGBM] [Info] Number of positive: 580, number of negative: 3234\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000430 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1018\n",
      "[LightGBM] [Info] Number of data points in the train set: 3814, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.152071 -> initscore=-1.718447\n",
      "[LightGBM] [Info] Start training from score -1.718447\n",
      "[LightGBM] [Info] Number of positive: 580, number of negative: 3234\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000502 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1025\n",
      "[LightGBM] [Info] Number of data points in the train set: 3814, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.152071 -> initscore=-1.718447\n",
      "[LightGBM] [Info] Start training from score -1.718447\n",
      "[LightGBM] [Info] Number of positive: 580, number of negative: 3234\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000628 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1021\n",
      "[LightGBM] [Info] Number of data points in the train set: 3814, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.152071 -> initscore=-1.718447\n",
      "[LightGBM] [Info] Start training from score -1.718447\n",
      "[LightGBM] [Info] Number of positive: 579, number of negative: 3235\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000442 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1026\n",
      "[LightGBM] [Info] Number of data points in the train set: 3814, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.151809 -> initscore=-1.720482\n",
      "[LightGBM] [Info] Start training from score -1.720482\n",
      "[LightGBM] [Info] Number of positive: 579, number of negative: 3235\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000322 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1019\n",
      "[LightGBM] [Info] Number of data points in the train set: 3814, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.151809 -> initscore=-1.720482\n",
      "[LightGBM] [Info] Start training from score -1.720482\n",
      "[LightGBM] [Info] Number of positive: 579, number of negative: 3235\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000433 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1017\n",
      "[LightGBM] [Info] Number of data points in the train set: 3814, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.151809 -> initscore=-1.720482\n",
      "[LightGBM] [Info] Start training from score -1.720482\n",
      "[LightGBM] [Info] Number of positive: 579, number of negative: 3235\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000452 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1021\n",
      "[LightGBM] [Info] Number of data points in the train set: 3814, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.151809 -> initscore=-1.720482\n",
      "[LightGBM] [Info] Start training from score -1.720482\n",
      "[LightGBM] [Info] Number of positive: 580, number of negative: 3235\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000413 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1018\n",
      "[LightGBM] [Info] Number of data points in the train set: 3815, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.152031 -> initscore=-1.718756\n",
      "[LightGBM] [Info] Start training from score -1.718756\n",
      "[LightGBM] [Info] Number of positive: 580, number of negative: 3235\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000425 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1023\n",
      "[LightGBM] [Info] Number of data points in the train set: 3815, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.152031 -> initscore=-1.718756\n",
      "[LightGBM] [Info] Start training from score -1.718756\n",
      "[LightGBM] [Info] Number of positive: 580, number of negative: 3234\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000519 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1022\n",
      "[LightGBM] [Info] Number of data points in the train set: 3814, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.152071 -> initscore=-1.718447\n",
      "[LightGBM] [Info] Start training from score -1.718447\n",
      "[LightGBM] [Info] Number of positive: 580, number of negative: 3234\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000537 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1018\n",
      "[LightGBM] [Info] Number of data points in the train set: 3814, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.152071 -> initscore=-1.718447\n",
      "[LightGBM] [Info] Start training from score -1.718447\n",
      "[LightGBM] [Info] Number of positive: 580, number of negative: 3234\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000632 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1024\n",
      "[LightGBM] [Info] Number of data points in the train set: 3814, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.152071 -> initscore=-1.718447\n",
      "[LightGBM] [Info] Start training from score -1.718447\n",
      "[LightGBM] [Info] Number of positive: 580, number of negative: 3234\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000412 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1025\n",
      "[LightGBM] [Info] Number of data points in the train set: 3814, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.152071 -> initscore=-1.718447\n",
      "[LightGBM] [Info] Start training from score -1.718447\n",
      "[LightGBM] [Info] Number of positive: 579, number of negative: 3235\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000444 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1019\n",
      "[LightGBM] [Info] Number of data points in the train set: 3814, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.151809 -> initscore=-1.720482\n",
      "[LightGBM] [Info] Start training from score -1.720482\n",
      "[LightGBM] [Info] Number of positive: 579, number of negative: 3235\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000428 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1022\n",
      "[LightGBM] [Info] Number of data points in the train set: 3814, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.151809 -> initscore=-1.720482\n",
      "[LightGBM] [Info] Start training from score -1.720482\n",
      "[LightGBM] [Info] Number of positive: 579, number of negative: 3235\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000385 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1015\n",
      "[LightGBM] [Info] Number of data points in the train set: 3814, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.151809 -> initscore=-1.720482\n",
      "[LightGBM] [Info] Start training from score -1.720482\n",
      "[LightGBM] [Info] Number of positive: 579, number of negative: 3235\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000417 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1018\n",
      "[LightGBM] [Info] Number of data points in the train set: 3814, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.151809 -> initscore=-1.720482\n",
      "[LightGBM] [Info] Start training from score -1.720482\n",
      "[LightGBM] [Info] Number of positive: 580, number of negative: 3235\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000471 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1026\n",
      "[LightGBM] [Info] Number of data points in the train set: 3815, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.152031 -> initscore=-1.718756\n",
      "[LightGBM] [Info] Start training from score -1.718756\n",
      "[LightGBM] [Info] Number of positive: 580, number of negative: 3235\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000404 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1017\n",
      "[LightGBM] [Info] Number of data points in the train set: 3815, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.152031 -> initscore=-1.718756\n",
      "[LightGBM] [Info] Start training from score -1.718756\n",
      "[LightGBM] [Info] Number of positive: 580, number of negative: 3234\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000398 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1019\n",
      "[LightGBM] [Info] Number of data points in the train set: 3814, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.152071 -> initscore=-1.718447\n",
      "[LightGBM] [Info] Start training from score -1.718447\n",
      "[LightGBM] [Info] Number of positive: 580, number of negative: 3234\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000390 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1023\n",
      "[LightGBM] [Info] Number of data points in the train set: 3814, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.152071 -> initscore=-1.718447\n",
      "[LightGBM] [Info] Start training from score -1.718447\n",
      "[LightGBM] [Info] Number of positive: 580, number of negative: 3234\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000359 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1023\n",
      "[LightGBM] [Info] Number of data points in the train set: 3814, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.152071 -> initscore=-1.718447\n",
      "[LightGBM] [Info] Start training from score -1.718447\n",
      "[LightGBM] [Info] Number of positive: 580, number of negative: 3234\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000396 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1027\n",
      "[LightGBM] [Info] Number of data points in the train set: 3814, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.152071 -> initscore=-1.718447\n",
      "[LightGBM] [Info] Start training from score -1.718447\n",
      "[LightGBM] [Info] Number of positive: 579, number of negative: 3235\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000391 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1020\n",
      "[LightGBM] [Info] Number of data points in the train set: 3814, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.151809 -> initscore=-1.720482\n",
      "[LightGBM] [Info] Start training from score -1.720482\n",
      "[LightGBM] [Info] Number of positive: 579, number of negative: 3235\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000382 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1022\n",
      "[LightGBM] [Info] Number of data points in the train set: 3814, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.151809 -> initscore=-1.720482\n",
      "[LightGBM] [Info] Start training from score -1.720482\n",
      "[LightGBM] [Info] Number of positive: 579, number of negative: 3235\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000395 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1019\n",
      "[LightGBM] [Info] Number of data points in the train set: 3814, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.151809 -> initscore=-1.720482\n",
      "[LightGBM] [Info] Start training from score -1.720482\n",
      "[LightGBM] [Info] Number of positive: 579, number of negative: 3235\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000511 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1015\n",
      "[LightGBM] [Info] Number of data points in the train set: 3814, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.151809 -> initscore=-1.720482\n",
      "[LightGBM] [Info] Start training from score -1.720482\n",
      "[LightGBM] [Info] Number of positive: 580, number of negative: 3235\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000541 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1020\n",
      "[LightGBM] [Info] Number of data points in the train set: 3815, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.152031 -> initscore=-1.718756\n",
      "[LightGBM] [Info] Start training from score -1.718756\n",
      "[LightGBM] [Info] Number of positive: 580, number of negative: 3235\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000446 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1024\n",
      "[LightGBM] [Info] Number of data points in the train set: 3815, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.152031 -> initscore=-1.718756\n",
      "[LightGBM] [Info] Start training from score -1.718756\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\macwa\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "C:\\Users\\macwa\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "C:\\Users\\macwa\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "C:\\Users\\macwa\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "C:\\Users\\macwa\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "C:\\Users\\macwa\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "C:\\Users\\macwa\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "C:\\Users\\macwa\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "C:\\Users\\macwa\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "C:\\Users\\macwa\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "C:\\Users\\macwa\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "C:\\Users\\macwa\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "C:\\Users\\macwa\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "C:\\Users\\macwa\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "C:\\Users\\macwa\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "C:\\Users\\macwa\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "C:\\Users\\macwa\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "C:\\Users\\macwa\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "C:\\Users\\macwa\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "C:\\Users\\macwa\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "C:\\Users\\macwa\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "C:\\Users\\macwa\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "C:\\Users\\macwa\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "C:\\Users\\macwa\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "C:\\Users\\macwa\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "C:\\Users\\macwa\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "C:\\Users\\macwa\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "C:\\Users\\macwa\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "C:\\Users\\macwa\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "C:\\Users\\macwa\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 580, number of negative: 3234\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000402 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1020\n",
      "[LightGBM] [Info] Number of data points in the train set: 3814, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.152071 -> initscore=-1.718447\n",
      "[LightGBM] [Info] Start training from score -1.718447\n",
      "[LightGBM] [Info] Number of positive: 580, number of negative: 3234\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000355 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1021\n",
      "[LightGBM] [Info] Number of data points in the train set: 3814, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.152071 -> initscore=-1.718447\n",
      "[LightGBM] [Info] Start training from score -1.718447\n",
      "[LightGBM] [Info] Number of positive: 580, number of negative: 3234\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000504 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1028\n",
      "[LightGBM] [Info] Number of data points in the train set: 3814, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.152071 -> initscore=-1.718447\n",
      "[LightGBM] [Info] Start training from score -1.718447\n",
      "[LightGBM] [Info] Number of positive: 580, number of negative: 3234\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000369 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1024\n",
      "[LightGBM] [Info] Number of data points in the train set: 3814, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.152071 -> initscore=-1.718447\n",
      "[LightGBM] [Info] Start training from score -1.718447\n",
      "[LightGBM] [Info] Number of positive: 579, number of negative: 3235\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000343 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1029\n",
      "[LightGBM] [Info] Number of data points in the train set: 3814, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.151809 -> initscore=-1.720482\n",
      "[LightGBM] [Info] Start training from score -1.720482\n",
      "[LightGBM] [Info] Number of positive: 579, number of negative: 3235\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000389 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1022\n",
      "[LightGBM] [Info] Number of data points in the train set: 3814, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.151809 -> initscore=-1.720482\n",
      "[LightGBM] [Info] Start training from score -1.720482\n",
      "[LightGBM] [Info] Number of positive: 579, number of negative: 3235\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000545 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1020\n",
      "[LightGBM] [Info] Number of data points in the train set: 3814, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.151809 -> initscore=-1.720482\n",
      "[LightGBM] [Info] Start training from score -1.720482\n",
      "[LightGBM] [Info] Number of positive: 579, number of negative: 3235\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000376 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1024\n",
      "[LightGBM] [Info] Number of data points in the train set: 3814, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.151809 -> initscore=-1.720482\n",
      "[LightGBM] [Info] Start training from score -1.720482\n",
      "[LightGBM] [Info] Number of positive: 580, number of negative: 3235\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000367 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1021\n",
      "[LightGBM] [Info] Number of data points in the train set: 3815, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.152031 -> initscore=-1.718756\n",
      "[LightGBM] [Info] Start training from score -1.718756\n",
      "[LightGBM] [Info] Number of positive: 580, number of negative: 3235\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000386 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1026\n",
      "[LightGBM] [Info] Number of data points in the train set: 3815, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.152031 -> initscore=-1.718756\n",
      "[LightGBM] [Info] Start training from score -1.718756\n",
      "[LightGBM] [Info] Number of positive: 580, number of negative: 3234\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000418 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1025\n",
      "[LightGBM] [Info] Number of data points in the train set: 3814, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.152071 -> initscore=-1.718447\n",
      "[LightGBM] [Info] Start training from score -1.718447\n",
      "[LightGBM] [Info] Number of positive: 580, number of negative: 3234\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000383 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1021\n",
      "[LightGBM] [Info] Number of data points in the train set: 3814, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.152071 -> initscore=-1.718447\n",
      "[LightGBM] [Info] Start training from score -1.718447\n",
      "[LightGBM] [Info] Number of positive: 580, number of negative: 3234\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000401 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1027\n",
      "[LightGBM] [Info] Number of data points in the train set: 3814, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.152071 -> initscore=-1.718447\n",
      "[LightGBM] [Info] Start training from score -1.718447\n",
      "[LightGBM] [Info] Number of positive: 580, number of negative: 3234\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000360 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1028\n",
      "[LightGBM] [Info] Number of data points in the train set: 3814, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.152071 -> initscore=-1.718447\n",
      "[LightGBM] [Info] Start training from score -1.718447\n",
      "[LightGBM] [Info] Number of positive: 579, number of negative: 3235\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000463 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1022\n",
      "[LightGBM] [Info] Number of data points in the train set: 3814, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.151809 -> initscore=-1.720482\n",
      "[LightGBM] [Info] Start training from score -1.720482\n",
      "[LightGBM] [Info] Number of positive: 579, number of negative: 3235\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000432 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1025\n",
      "[LightGBM] [Info] Number of data points in the train set: 3814, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.151809 -> initscore=-1.720482\n",
      "[LightGBM] [Info] Start training from score -1.720482\n",
      "[LightGBM] [Info] Number of positive: 579, number of negative: 3235\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000374 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1018\n",
      "[LightGBM] [Info] Number of data points in the train set: 3814, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.151809 -> initscore=-1.720482\n",
      "[LightGBM] [Info] Start training from score -1.720482\n",
      "[LightGBM] [Info] Number of positive: 579, number of negative: 3235\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000312 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1021\n",
      "[LightGBM] [Info] Number of data points in the train set: 3814, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.151809 -> initscore=-1.720482\n",
      "[LightGBM] [Info] Start training from score -1.720482\n",
      "[LightGBM] [Info] Number of positive: 580, number of negative: 3235\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000466 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1029\n",
      "[LightGBM] [Info] Number of data points in the train set: 3815, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.152031 -> initscore=-1.718756\n",
      "[LightGBM] [Info] Start training from score -1.718756\n",
      "[LightGBM] [Info] Number of positive: 580, number of negative: 3235\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000397 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1020\n",
      "[LightGBM] [Info] Number of data points in the train set: 3815, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.152031 -> initscore=-1.718756\n",
      "[LightGBM] [Info] Start training from score -1.718756\n",
      "[LightGBM] [Info] Number of positive: 580, number of negative: 3234\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000454 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1022\n",
      "[LightGBM] [Info] Number of data points in the train set: 3814, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.152071 -> initscore=-1.718447\n",
      "[LightGBM] [Info] Start training from score -1.718447\n",
      "[LightGBM] [Info] Number of positive: 580, number of negative: 3234\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000443 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1026\n",
      "[LightGBM] [Info] Number of data points in the train set: 3814, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.152071 -> initscore=-1.718447\n",
      "[LightGBM] [Info] Start training from score -1.718447\n",
      "[LightGBM] [Info] Number of positive: 580, number of negative: 3234\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000408 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1026\n",
      "[LightGBM] [Info] Number of data points in the train set: 3814, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.152071 -> initscore=-1.718447\n",
      "[LightGBM] [Info] Start training from score -1.718447\n",
      "[LightGBM] [Info] Number of positive: 580, number of negative: 3234\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000394 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1030\n",
      "[LightGBM] [Info] Number of data points in the train set: 3814, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.152071 -> initscore=-1.718447\n",
      "[LightGBM] [Info] Start training from score -1.718447\n",
      "[LightGBM] [Info] Number of positive: 579, number of negative: 3235\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000395 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1023\n",
      "[LightGBM] [Info] Number of data points in the train set: 3814, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.151809 -> initscore=-1.720482\n",
      "[LightGBM] [Info] Start training from score -1.720482\n",
      "[LightGBM] [Info] Number of positive: 579, number of negative: 3235\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000325 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1025\n",
      "[LightGBM] [Info] Number of data points in the train set: 3814, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.151809 -> initscore=-1.720482\n",
      "[LightGBM] [Info] Start training from score -1.720482\n",
      "[LightGBM] [Info] Number of positive: 579, number of negative: 3235\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000455 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1022\n",
      "[LightGBM] [Info] Number of data points in the train set: 3814, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.151809 -> initscore=-1.720482\n",
      "[LightGBM] [Info] Start training from score -1.720482\n",
      "[LightGBM] [Info] Number of positive: 579, number of negative: 3235\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000380 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1018\n",
      "[LightGBM] [Info] Number of data points in the train set: 3814, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.151809 -> initscore=-1.720482\n",
      "[LightGBM] [Info] Start training from score -1.720482\n",
      "[LightGBM] [Info] Number of positive: 580, number of negative: 3235\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000356 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1023\n",
      "[LightGBM] [Info] Number of data points in the train set: 3815, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.152031 -> initscore=-1.718756\n",
      "[LightGBM] [Info] Start training from score -1.718756\n",
      "[LightGBM] [Info] Number of positive: 580, number of negative: 3235\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000429 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1027\n",
      "[LightGBM] [Info] Number of data points in the train set: 3815, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.152031 -> initscore=-1.718756\n",
      "[LightGBM] [Info] Start training from score -1.718756\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\macwa\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "C:\\Users\\macwa\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "C:\\Users\\macwa\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "C:\\Users\\macwa\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "C:\\Users\\macwa\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "C:\\Users\\macwa\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "C:\\Users\\macwa\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "C:\\Users\\macwa\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "C:\\Users\\macwa\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "C:\\Users\\macwa\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "C:\\Users\\macwa\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "C:\\Users\\macwa\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "C:\\Users\\macwa\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "C:\\Users\\macwa\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "C:\\Users\\macwa\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "C:\\Users\\macwa\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "C:\\Users\\macwa\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "C:\\Users\\macwa\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "C:\\Users\\macwa\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "C:\\Users\\macwa\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "C:\\Users\\macwa\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "C:\\Users\\macwa\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "C:\\Users\\macwa\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "C:\\Users\\macwa\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "C:\\Users\\macwa\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "C:\\Users\\macwa\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "C:\\Users\\macwa\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "C:\\Users\\macwa\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "C:\\Users\\macwa\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "C:\\Users\\macwa\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Strategy            Algorithm  Mean Accuracy  Standard Deviation\n",
      "0            mean  Logistic Regression          85.46                0.58\n",
      "1            mean                  KNN          83.40                0.89\n",
      "2            mean        Random Forest          84.92                0.69\n",
      "3            mean    Gradient Boosting          84.61                0.79\n",
      "4            mean                  SVM          84.82                0.37\n",
      "5            mean              XGBoost          83.53                1.11\n",
      "6            mean             LightGBM          84.43                0.85\n",
      "7            mean             CatBoost          84.49                0.67\n",
      "8            mean          Naive Bayes          82.41                1.30\n",
      "9            mean              Bagging          83.40                1.14\n",
      "10           mean             Stacking          85.37                0.62\n",
      "11         median  Logistic Regression          85.46                0.58\n",
      "12         median                  KNN          83.45                0.91\n",
      "13         median        Random Forest          84.82                0.69\n",
      "14         median    Gradient Boosting          84.58                0.82\n",
      "15         median                  SVM          84.82                0.37\n",
      "16         median              XGBoost          83.20                0.93\n",
      "17         median             LightGBM          84.12                0.91\n",
      "18         median             CatBoost          84.63                0.63\n",
      "19         median          Naive Bayes          82.41                1.30\n",
      "20         median              Bagging          83.40                0.86\n",
      "21         median             Stacking          85.39                0.62\n",
      "22  most_frequent  Logistic Regression          85.47                0.58\n",
      "23  most_frequent                  KNN          83.45                0.83\n",
      "24  most_frequent        Random Forest          84.88                0.61\n",
      "25  most_frequent    Gradient Boosting          84.62                0.74\n",
      "26  most_frequent                  SVM          84.81                0.37\n",
      "27  most_frequent              XGBoost          83.50                1.02\n",
      "28  most_frequent             LightGBM          84.36                0.92\n",
      "29  most_frequent             CatBoost          84.60                0.65\n",
      "30  most_frequent          Naive Bayes          82.39                1.30\n",
      "31  most_frequent              Bagging          83.36                1.11\n",
      "32  most_frequent             Stacking          85.39                0.65\n",
      "33       constant  Logistic Regression          85.37                0.57\n",
      "34       constant                  KNN          83.36                0.80\n",
      "35       constant        Random Forest          84.75                0.71\n",
      "36       constant    Gradient Boosting          84.58                0.71\n",
      "37       constant                  SVM          84.58                0.38\n",
      "38       constant              XGBoost          83.18                1.05\n",
      "39       constant             LightGBM          84.12                0.87\n",
      "40       constant             CatBoost          84.49                0.67\n",
      "41       constant          Naive Bayes          82.14                1.41\n",
      "42       constant              Bagging          83.81                0.79\n",
      "43       constant             Stacking          85.28                0.63\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold, cross_val_score\n",
    "\n",
    "# Load your dataset\n",
    "df = pd.read_csv(\"heart_disease.csv\")\n",
    "\n",
    "# Separate features (X) and target (y)\n",
    "X = df[df.columns[:-1]]\n",
    "y = df[df.columns[-1]]\n",
    "\n",
    "# Define strategies and algorithms\n",
    "strategies = ['mean', 'median', 'most_frequent', 'constant']\n",
    "# Algorithms\n",
    "algorithms = [\n",
    "    ('Logistic Regression', LogisticRegression()),\n",
    "    ('KNN', KNeighborsClassifier()),\n",
    "    ('Random Forest', RandomForestClassifier()),\n",
    "    ('Gradient Boosting', GradientBoostingClassifier()),\n",
    "    ('SVM', SVC()),\n",
    "    ('XGBoost', XGBClassifier()),\n",
    "    ('LightGBM', LGBMClassifier()),\n",
    "    ('CatBoost', CatBoostClassifier(silent=True)),\n",
    "    ('Naive Bayes', GaussianNB()),\n",
    "    ('Bagging', BaggingClassifier(base_estimator=None, n_estimators=10, random_state=1)),\n",
    "    ('Stacking', StackingClassifier(estimators=[('lr', LogisticRegression()), ('rf', RandomForestClassifier())], final_estimator=LogisticRegression()))\n",
    "]\n",
    "\n",
    "# Create an empty list to store results\n",
    "results = []\n",
    "\n",
    "# Iterate over strategies and algorithms\n",
    "for strategy in strategies:\n",
    "    for algo_name, algo_model in algorithms:\n",
    "        # Create a SimpleImputer with the current strategy\n",
    "        imputer = SimpleImputer(strategy=strategy)\n",
    "\n",
    "        # Create a pipeline with imputer, StandardScaler, and the current algorithm\n",
    "        pipeline = Pipeline([\n",
    "            ('imputer', imputer),\n",
    "            ('scaler', StandardScaler()),\n",
    "            ('model', algo_model)\n",
    "        ])\n",
    "\n",
    "        # Create RepeatedStratifiedKFold\n",
    "        cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "\n",
    "        # Create Cross_val_score\n",
    "        scores = cross_val_score(pipeline, X, y, scoring='accuracy', cv=cv)\n",
    "\n",
    "        # Append results to the list\n",
    "        results.append({\n",
    "            'Strategy': strategy,\n",
    "            'Algorithm': algo_name,\n",
    "            'Mean Accuracy': scores.mean(),\n",
    "            'Standard Deviation': scores.std()\n",
    "        })\n",
    "\n",
    "# Convert the list of dictionaries to a DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "# Convert the mean accuracy and standard deviation to percentage format\n",
    "results_df['Mean Accuracy'] = (results_df['Mean Accuracy'] * 100).round(2)\n",
    "results_df['Standard Deviation'] = (results_df['Standard Deviation'] * 100).round(2)\n",
    "\n",
    "# Display the results\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q1: Which is the best strategy for this dataset using Random Forest algorithm?\n",
    "\n",
    "### Q1: The best strategy for this dataset using Random Forest algorithm is Median 84.92% accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q2:  Which is the best algorithm for this dataset using Mean Strategy?\n",
    "### A2: The best algorithm for this dataset using the Mean Strategy is Logistic Regression (Mean Accuracy: 85.46%)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q3: Which is the best combination of algorithm and best Imputation Strategy overall?\n",
    "### A3: The best combination of algorithm and imputation strategy overall is Mean Strategy with Logistic Regression (Mean Accuracy: 85.46%)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
